{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-16T12:31:46.803504Z",
     "start_time": "2025-05-16T12:30:19.163451Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, \\\n",
    "    precision_recall_curve\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, RepeatVector, TimeDistributed, Dropout\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, matthews_corrcoef, cohen_kappa_score, average_precision_score)\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# ----------------#\n",
    "# 1. IMPORT DATA  #\n",
    "# ----------------#\n",
    "data = pd.read_csv('../dataset/cdc_diabetes_health_indicators.csv')\n",
    "print(\"Data shape:\", data.shape)\n",
    "print(\"\\nSample data:\")\n",
    "print(data.head())\n",
    "print(\"\\nData info:\")\n",
    "print(data.info())\n",
    "print(\"\\nStatistik deskriptif:\")\n",
    "print(data.describe())\n",
    "\n",
    "# Periksa distribusi kelas target\n",
    "print(\"\\nDistribusi kelas target:\")\n",
    "target_counts = data['target'].value_counts()\n",
    "print(target_counts)\n",
    "print(f\"Rasio kelas: {target_counts[0] / target_counts[1]:.2f}:1\")\n",
    "\n",
    "# -----------------#\n",
    "# 2. Preprocessing #\n",
    "# -----------------#\n",
    "\n",
    "print(\"\\n=== 2. Preprocessing ===\")\n",
    "# Pisahkan fitur dan target\n",
    "X = data.drop('target', axis=1)\n",
    "if 'ID' in X.columns:\n",
    "    X = X.drop('ID', axis=1)  # Hapus kolom ID jika ada\n",
    "y = data['target']\n",
    "\n",
    "print(\"Fitur shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "\n",
    "# Normalisasi/Standardisasi data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "print(\"Data setelah scaling (sample):\")\n",
    "print(X_scaled_df.head())\n",
    "\n",
    "# Analisis korelasi\n",
    "corr_matrix = X_scaled_df.copy()\n",
    "corr_matrix['target'] = y\n",
    "correlation = corr_matrix.corr()['target'].sort_values(ascending=False)\n",
    "print(\"\\nKorelasi fitur dengan target:\")\n",
    "print(correlation)\n",
    "\n",
    "# Plot korelasi fitur terhadap target\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation.drop('target').plot(kind='bar')\n",
    "plt.title('Korelasi Fitur dengan Target')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_correlations.png')\n",
    "plt.close()\n",
    "\n",
    "# Buat beberapa fitur interaksi baru yang mungkin membantu prediksi diabetes\n",
    "print(\"\\nMembuat fitur interaksi baru...\")\n",
    "X_with_interactions = X_scaled_df.copy()\n",
    "\n",
    "# Fitur interaksi antara BMI dan usia\n",
    "X_with_interactions['BMI_X_Age'] = X_scaled_df['BMI'] * X_scaled_df['Age']\n",
    "\n",
    "# Fitur interaksi antara BMI dan tekanan darah tinggi\n",
    "X_with_interactions['BMI_X_HighBP'] = X_scaled_df['BMI'] * X_scaled_df['HighBP']\n",
    "\n",
    "# Fitur interaksi antara usia dan tekanan darah tinggi\n",
    "X_with_interactions['Age_X_HighBP'] = X_scaled_df['Age'] * X_scaled_df['HighBP']\n",
    "\n",
    "# Fitur interaksi antara BMI dan kolesterol tinggi\n",
    "X_with_interactions['BMI_X_HighChol'] = X_scaled_df['BMI'] * X_scaled_df['HighChol']\n",
    "\n",
    "# Fitur interaksi gabungan antara kesehatan umum, mental, dan fisik\n",
    "X_with_interactions['Health_Combined'] = (X_scaled_df['GenHlth'] + X_scaled_df['MentHlth'] + X_scaled_df[\n",
    "    'PhysHlth']) / 3\n",
    "\n",
    "# Konversi kembali ke numpy array\n",
    "X_scaled_with_interactions = X_with_interactions.values\n",
    "\n",
    "print(f\"Jumlah fitur setelah menambahkan interaksi: {X_with_interactions.shape[1]}\")\n",
    "\n",
    "# ----------------------------#\n",
    "# 3. Split Train/Test (75:25) #\n",
    "# ----------------------------#\n",
    "\n",
    "print(\"\\n=== 3. Split Train/Test (75:25) ===\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled_with_interactions, y,\n",
    "                                                    test_size=0.25, random_state=42, stratify=y)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"Distribusi kelas di training set: {np.bincount(y_train)}\")\n",
    "print(f\"Distribusi kelas di testing set: {np.bincount(y_test)}\")\n",
    "\n",
    "# ----------------------------------------#\n",
    "# 4. Feature Selection - Random Forest    #\n",
    "# ----------------------------------------#\n",
    "\n",
    "print(\"\\n=== 4. Feature Selection dengan Random Forest ===\")\n",
    "feature_names = list(X_with_interactions.columns)\n",
    "\n",
    "# Membuat dan melatih Random Forest dengan class_weight='balanced'\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Plotting feature importances\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': rf.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"Feature importances:\")\n",
    "print(feature_importances)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances[:15])\n",
    "plt.title('Top 15 Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importances.png')\n",
    "plt.close()\n",
    "\n",
    "# Pilih fitur berdasarkan threshold importance (lebih rendah untuk mempertahankan lebih banyak fitur)\n",
    "selector = SelectFromModel(rf, threshold=\"mean\", prefit=True)\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "selected_feature_indices = selector.get_support()\n",
    "selected_features = [feature for feature, selected in zip(feature_names, selected_feature_indices) if selected]\n",
    "\n",
    "print(f\"Jumlah fitur terpilih: {X_train_selected.shape[1]} dari {X_train.shape[1]}\")\n",
    "print(\"Fitur terpilih:\", selected_features)\n",
    "\n",
    "# --------------------------------------------#\n",
    "# 5. Resampling - Mengatasi Imbalanced Data   #\n",
    "# --------------------------------------------#\n",
    "\n",
    "print(\"\\n=== 5. Resampling untuk Mengatasi Ketidakseimbangan Kelas ===\")\n",
    "\n",
    "# Sesuaikan rasio oversampling dan undersampling\n",
    "smote = SMOTE(sampling_strategy=0.5, random_state=42)  # Membuat rasio minoritas:mayoritas = 1:2\n",
    "rus = RandomUnderSampler(sampling_strategy=0.8, random_state=42)  # Membuat rasio minoritas:mayoritas = 1:1.25\n",
    "\n",
    "# Pipeline resampling: SMOTE diikuti oleh Random Under Sampling\n",
    "resampling_pipeline = ImbPipeline([\n",
    "    ('smote', smote),\n",
    "    ('under_sampler', rus)\n",
    "])\n",
    "\n",
    "# Lakukan resampling pada data training\n",
    "X_train_resampled, y_train_resampled = resampling_pipeline.fit_resample(X_train_selected, y_train)\n",
    "\n",
    "print(f\"Bentuk data training sebelum resampling: {X_train_selected.shape}\")\n",
    "print(f\"Distribusi kelas sebelum resampling: {np.bincount(y_train)}\")\n",
    "print(f\"Bentuk data training setelah resampling: {X_train_resampled.shape}\")\n",
    "print(f\"Distribusi kelas setelah resampling: {np.bincount(y_train_resampled)}\")\n",
    "\n",
    "# Visualisasi distribusi kelas sebelum dan sesudah resampling\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.bar(['Non-Diabetes (0)', 'Diabetes (1)'], np.bincount(y_train), color=['blue', 'red'])\n",
    "plt.title('Distribusi Kelas Sebelum Resampling')\n",
    "plt.ylabel('Jumlah Sampel')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.bar(['Non-Diabetes (0)', 'Diabetes (1)'], np.bincount(y_train_resampled), color=['blue', 'red'])\n",
    "plt.title('Distribusi Kelas Setelah Resampling')\n",
    "plt.ylabel('Jumlah Sampel')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_distribution_resampling.png')\n",
    "plt.close()\n",
    "\n",
    "# --------------------------------------------------#\n",
    "# 6. Train Final Model (XGBoost dengan fokus recall) #\n",
    "# --------------------------------------------------#\n",
    "\n",
    "print(\"\\n=== 6. Train Final Model (XGBoost with focus on recall) ===\")\n",
    "\n",
    "# Parameters for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_child_weight': [1, 3, 5, 7],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'scale_pos_weight': [1, 3, 5, 7]  # Important for imbalanced data\n",
    "}\n",
    "\n",
    "# Stratified K-Fold for cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# RandomizedSearchCV for parameter tuning\n",
    "# Note: Remove XGBoost-specific parameters from here\n",
    "xgb_random = RandomizedSearchCV(\n",
    "    xgb.XGBClassifier(objective='binary:logistic', random_state=42,\n",
    "                     use_label_encoder=False, eval_metric='logloss'),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,  # Number of parameter combinations to test\n",
    "    scoring='recall',  # Optimize for recall\n",
    "    cv=skf,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model on the resampled data\n",
    "# Note: Remove eval_set and early_stopping_rounds from here\n",
    "xgb_random.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Best model parameters\n",
    "print(\"Best parameters:\", xgb_random.best_params_)\n",
    "print(\"Best recall score: {:.4f}\".format(xgb_random.best_score_))\n",
    "\n",
    "# Get the best model from RandomizedSearchCV\n",
    "best_model_params = xgb_random.best_params_\n",
    "\n",
    "# Create a new model with the best parameters and train it with early stopping\n",
    "best_xgb = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    **best_model_params\n",
    ")\n",
    "\n",
    "# Now fit this model with early stopping\n",
    "best_xgb.fit(\n",
    "    X_train_resampled,\n",
    "    y_train_resampled,\n",
    "    eval_set=[(X_test_selected, y_test)],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Cross-validation with the best model\n",
    "cv_recall = cross_val_score(best_xgb, X_train_resampled, y_train_resampled,\n",
    "                           cv=skf, scoring='recall')\n",
    "cv_accuracy = cross_val_score(best_xgb, X_train_resampled, y_train_resampled,\n",
    "                             cv=skf, scoring='accuracy')\n",
    "cv_f1 = cross_val_score(best_xgb, X_train_resampled, y_train_resampled,\n",
    "                       cv=skf, scoring='f1')\n",
    "\n",
    "print(\"Cross-validation metrics:\")\n",
    "print(f\"Accuracy: {cv_accuracy.mean():.4f} ± {cv_accuracy.std():.4f}\")\n",
    "print(f\"Recall: {cv_recall.mean():.4f} ± {cv_recall.std():.4f}\")\n",
    "print(f\"F1-score: {cv_f1.mean():.4f} ± {cv_f1.std():.4f}\")\n",
    "# -----------------------------#\n",
    "# 7. Threshold Optimization    #\n",
    "# -----------------------------#\n",
    "\n",
    "print(\"\\n=== 7. Threshold Optimization untuk Meningkatkan Recall ===\")\n",
    "\n",
    "# Prediksi probabilitas pada data tes\n",
    "y_pred_proba = best_xgb.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# Evaluasi berbagai threshold untuk menemukan yang optimal untuk recall\n",
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "f1_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "    recall_scores.append(recall_score(y_test, y_pred))\n",
    "    precision_scores.append(precision_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Plot metrics vs threshold\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(thresholds, recall_scores, 'b-', label='Recall')\n",
    "plt.plot(thresholds, precision_scores, 'g-', label='Precision')\n",
    "plt.plot(thresholds, f1_scores, 'r-', label='F1 Score')\n",
    "plt.plot(thresholds, accuracy_scores, 'y-', label='Accuracy')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Metric Scores vs. Classification Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('threshold_optimization.png')\n",
    "plt.close()\n",
    "\n",
    "# Temukan threshold yang memaksimalkan F1-score\n",
    "optimal_idx = np.argmax(f1_scores)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(f\"Threshold optimal untuk F1-score: {optimal_threshold:.2f}\")\n",
    "print(f\"F1-score pada threshold optimal: {f1_scores[optimal_idx]:.4f}\")\n",
    "print(f\"Recall pada threshold optimal: {recall_scores[optimal_idx]:.4f}\")\n",
    "print(f\"Precision pada threshold optimal: {precision_scores[optimal_idx]:.4f}\")\n",
    "print(f\"Accuracy pada threshold optimal: {accuracy_scores[optimal_idx]:.4f}\")\n",
    "\n",
    "# Jika recall masih menjadi prioritas, kita bisa menurunkan threshold lebih jauh\n",
    "# Temukan threshold dengan recall minimal 0.7 tetapi dengan precision tertinggi\n",
    "target_recall = 0.7\n",
    "valid_indices = [i for i, r in enumerate(recall_scores) if r >= target_recall]\n",
    "\n",
    "if valid_indices:\n",
    "    # Ambil threshold dengan precision tertinggi dari threshold yang memenuhi recall target\n",
    "    best_precision_idx = valid_indices[np.argmax([precision_scores[i] for i in valid_indices])]\n",
    "    recall_optimized_threshold = thresholds[best_precision_idx]\n",
    "\n",
    "    print(f\"\\nThreshold optimal untuk recall >= {target_recall}: {recall_optimized_threshold:.2f}\")\n",
    "    print(f\"Recall pada threshold ini: {recall_scores[best_precision_idx]:.4f}\")\n",
    "    print(f\"Precision pada threshold ini: {precision_scores[best_precision_idx]:.4f}\")\n",
    "    print(f\"F1-score pada threshold ini: {f1_scores[best_precision_idx]:.4f}\")\n",
    "    print(f\"Accuracy pada threshold ini: {accuracy_scores[best_precision_idx]:.4f}\")\n",
    "else:\n",
    "    print(f\"\\nTidak ditemukan threshold yang menghasilkan recall >= {target_recall}\")\n",
    "    # Pilih threshold dengan recall tertinggi\n",
    "    recall_optimized_threshold = thresholds[np.argmax(recall_scores)]\n",
    "    max_recall_idx = np.argmax(recall_scores)\n",
    "\n",
    "    print(f\"Threshold dengan recall tertinggi: {recall_optimized_threshold:.2f}\")\n",
    "    print(f\"Recall pada threshold ini: {recall_scores[max_recall_idx]:.4f}\")\n",
    "    print(f\"Precision pada threshold ini: {precision_scores[max_recall_idx]:.4f}\")\n",
    "    print(f\"F1-score pada threshold ini: {f1_scores[max_recall_idx]:.4f}\")\n",
    "    print(f\"Accuracy pada threshold ini: {accuracy_scores[max_recall_idx]:.4f}\")\n",
    "\n",
    "# Gunakan threshold yang dipilih untuk evaluasi final\n",
    "final_threshold = recall_optimized_threshold\n",
    "y_pred_final = (y_pred_proba >= final_threshold).astype(int)\n",
    "\n",
    "# ------------------#\n",
    "# 8. Final Testing  #\n",
    "# ------------------#\n",
    "\n",
    "print(\"\\n=== 8. Final Testing ===\")\n",
    "\n",
    "# Evaluasi model dengan threshold terpilih\n",
    "accuracy = accuracy_score(y_test, y_pred_final)\n",
    "precision = precision_score(y_test, y_pred_final)\n",
    "recall = recall_score(y_test, y_pred_final)\n",
    "f1 = f1_score(y_test, y_pred_final)\n",
    "roc_auc_value = roc_auc_score(y_test, y_pred_proba)\n",
    "mcc = matthews_corrcoef(y_test, y_pred_final)\n",
    "kappa = cohen_kappa_score(y_test, y_pred_final)\n",
    "average_precision = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "# Tampilkan hasil metrik untuk publikasi jurnal\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"HASIL EVALUASI MODEL UNTUK PUBLIKASI JURNAL\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-Score      : {f1:.4f}\")\n",
    "print(f\"ROC AUC       : {roc_auc_value:.4f}\")\n",
    "print(f\"MCC           : {mcc:.4f}\")\n",
    "print(f\"Cohen's Kappa : {kappa:.4f}\")\n",
    "print(f\"Avg Precision : {average_precision:.4f}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_final))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_final)\n",
    "cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "cm_perc = cm / cm_sum * 100\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.subplot(221)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix (Count)')\n",
    "plt.ylabel('Aktual')\n",
    "plt.xlabel('Prediksi')\n",
    "\n",
    "plt.subplot(222)\n",
    "sns.heatmap(cm_perc, annot=True, fmt='.2f', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix (Percentage %)')\n",
    "plt.ylabel('Aktual')\n",
    "plt.xlabel('Prediksi')\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.plot(recall_curve, precision_curve, color='green', lw=2,\n",
    "         label=f'PR curve (avg precision = {average_precision:.3f})')\n",
    "plt.axvline(x=recall, color='red', linestyle='--',\n",
    "            label=f'Selected operating point\\nRecall={recall:.2f}, Precision={precision:.2f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_evaluation_metrics.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Simpan model terbaik dan pipeline preprocessing\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Simpan model dan komponen preprocessing\n",
    "joblib.dump(best_xgb, 'best_xgb_model.joblib')\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "joblib.dump(selector, 'feature_selector.joblib')\n",
    "joblib.dump(resampling_pipeline, 'resampling_pipeline.joblib')\n",
    "joblib.dump(final_threshold, 'classification_threshold.joblib')\n",
    "\n",
    "# Simpan hasil eksperimen untuk jurnal\n",
    "experiment_results = {\n",
    "    'Model': 'XGBoost dengan Optimasi Threshold dan Resampling',\n",
    "    'Tanggal': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    'Dataset_Size': X.shape[0],\n",
    "    'Original_Features': X.shape[1],\n",
    "    'Enhanced_Features': X_with_interactions.shape[1],\n",
    "    'Selected_Features': len(selected_features),\n",
    "    'Resampling_Strategy': 'SMOTE + Random Undersampling',\n",
    "    'Classification_Threshold': final_threshold,\n",
    "    'Best_Parameters': xgb_random.best_params_,\n",
    "    'CV_Recall_Mean': cv_recall.mean(),\n",
    "    'CV_Recall_Std': cv_recall.std(),\n",
    "    'Test_Accuracy': accuracy,\n",
    "    'Test_Precision': precision,\n",
    "    'Test_Recall': recall,\n",
    "    'Test_F1': f1,\n",
    "    'Test_ROC_AUC': roc_auc_value,\n",
    "    'Test_MCC': mcc,\n",
    "    'Test_Kappa': kappa,\n",
    "    'Test_Avg_Precision': average_precision\n",
    "}\n",
    "\n",
    "# Simpan dalam format CSV\n",
    "pd.DataFrame([experiment_results]).to_csv('hasil_eksperimen_recall_focus.csv', index=False)\n",
    "\n",
    "# Simpan hasil dengan format tabel untuk jurnal\n",
    "with open('hasil_table_untuk_jurnal.txt', 'w') as f:\n",
    "    f.write(\"Table X: Performance metrics of the proposed recall-optimized model for diabetes prediction\\n\\n\")\n",
    "    f.write(\"| Metric | Value |\\n\")\n",
    "    f.write(\"|--------|-------|\\n\")\n",
    "    f.write(f\"| Accuracy | {accuracy:.4f} |\\n\")\n",
    "    f.write(f\"| Precision | {precision:.4f} |\\n\")\n",
    "    f.write(f\"| Recall | {recall:.4f} |\\n\")\n",
    "    f.write(f\"| F1-Score | {f1:.4f} |\\n\")\n",
    "    f.write(f\"| ROC AUC | {roc_auc_value:.4f} |\\n\")\n",
    "    f.write(f\"| Matthews Correlation Coefficient | {mcc:.4f} |\\n\")\n",
    "    f.write(f\"| Cohen's Kappa | {kappa:.4f} |\\n\")\n",
    "    f.write(f\"| Average Precision | {average_precision:.4f} |\\n\\n\")\n",
    "    f.write(\n",
    "        \"*Note: The proposed model optimizes for recall using threshold adjustment, robust resampling techniques and feature engineering.\")\n",
    "\n",
    "print(\"\\nProses selesai! Model terbaik dengan fokus recall tersimpan sebagai 'best_xgb_model.joblib'\")\n",
    "\n",
    "\n",
    "# Buat fungsi untuk prediksi data baru dengan threshold yang telah dioptimalkan\n",
    "def predict_diabetes(new_data, threshold=final_threshold):\n",
    "    \"\"\"\n",
    "    Memprediksi diabetes pada data baru dengan threshold yang dioptimalkan untuk recall\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    new_data : pandas DataFrame\n",
    "        Data baru yang akan diprediksi, harus memiliki kolom yang sama dengan dataset asli\n",
    "    threshold : float, default=optimal_threshold\n",
    "        Threshold probabilitas untuk mengklasifikasikan sebagai diabetes (kelas 1)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    prediksi : array\n",
    "        Hasil prediksi (0: tidak diabetes, 1: diabetes)\n",
    "    probabilitas : array\n",
    "        Probabilitas prediksi\n",
    "    \"\"\"\n",
    "    # Preprocessing\n",
    "    if 'ID' in new_data.columns:\n",
    "        new_data = new_data.drop('ID', axis=1)\n",
    "    if 'Diabetes_binary' in new_data.columns or 'target' in new_data.columns:\n",
    "        new_data = new_data.drop(\n",
    "            ['Diabetes_binary', 'target'] if 'Diabetes_binary' in new_data.columns and 'target' in new_data.columns\n",
    "            else 'Diabetes_binary' if 'Diabetes_binary' in new_data.columns\n",
    "            else 'target', axis=1)\n",
    "\n",
    "    # Scaling\n",
    "    X_new_scaled = scaler.transform(new_data)\n",
    "\n",
    "    # Tambahkan fitur interaksi yang sama seperti pada training\n",
    "    X_new_df = pd.DataFrame(X_new_scaled, columns=X.columns)\n",
    "    X_new_with_interactions = X_new_df.copy()\n",
    "\n",
    "    # Buat fitur interaksi yang sama\n",
    "    X_new_with_interactions['BMI_X_Age'] = X_new_df['BMI'] * X_new_df['Age']\n",
    "    X_new_with_interactions['BMI_X_HighBP'] = X_new_df['BMI'] * X_new_df['HighBP']\n",
    "    X_new_with_interactions['Age_X_HighBP'] = X_new_df['Age'] * X_new_df['HighBP']\n",
    "    X_new_with_interactions['BMI_X_HighChol'] = X_new_df['BMI'] * X_new_df['HighChol']\n",
    "    X_new_with_interactions['Health_Combined'] = (X_new_df['GenHlth'] + X_new_df['MentHlth'] + X_new_df['PhysHlth']) / 3\n",
    "\n",
    "    # Feature selection\n",
    "    X_new_selected = selector.transform(X_new_with_interactions.values)\n",
    "\n",
    "    # Prediksi\n",
    "    probability = best_xgb.predict_proba(X_new_selected)[:, 1]\n",
    "    prediction = (probability >= threshold).astype(int)\n",
    "\n",
    "    return prediction, probability\n",
    "\n",
    "\n",
    "print(\"\\nContoh penggunaan fungsi prediksi dengan threshold optimal:\")\n",
    "print(\"prediction, probability = predict_diabetes(new_patient_data)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (253680, 22)\n",
      "\n",
      "Sample data:\n",
      "   HighBP  HighChol  CholCheck  BMI  Smoker  Stroke  HeartDiseaseorAttack  \\\n",
      "0       1         1          1   40       1       0                     0   \n",
      "1       0         0          0   25       1       0                     0   \n",
      "2       1         1          1   28       0       0                     0   \n",
      "3       1         0          1   27       0       0                     0   \n",
      "4       1         1          1   24       0       0                     0   \n",
      "\n",
      "   PhysActivity  Fruits  Veggies  ...  NoDocbcCost  GenHlth  MentHlth  \\\n",
      "0             0       0        1  ...            0        5        18   \n",
      "1             1       0        0  ...            1        3         0   \n",
      "2             0       1        0  ...            1        5        30   \n",
      "3             1       1        1  ...            0        2         0   \n",
      "4             1       1        1  ...            0        2         3   \n",
      "\n",
      "   PhysHlth  DiffWalk  Sex  Age  Education  Income  target  \n",
      "0        15         1    0    9          4       3       0  \n",
      "1         0         0    0    7          6       1       0  \n",
      "2        30         1    0    9          4       8       0  \n",
      "3         0         0    0   11          3       6       0  \n",
      "4         0         0    0   11          5       4       0  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253680 entries, 0 to 253679\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count   Dtype\n",
      "---  ------                --------------   -----\n",
      " 0   HighBP                253680 non-null  int64\n",
      " 1   HighChol              253680 non-null  int64\n",
      " 2   CholCheck             253680 non-null  int64\n",
      " 3   BMI                   253680 non-null  int64\n",
      " 4   Smoker                253680 non-null  int64\n",
      " 5   Stroke                253680 non-null  int64\n",
      " 6   HeartDiseaseorAttack  253680 non-null  int64\n",
      " 7   PhysActivity          253680 non-null  int64\n",
      " 8   Fruits                253680 non-null  int64\n",
      " 9   Veggies               253680 non-null  int64\n",
      " 10  HvyAlcoholConsump     253680 non-null  int64\n",
      " 11  AnyHealthcare         253680 non-null  int64\n",
      " 12  NoDocbcCost           253680 non-null  int64\n",
      " 13  GenHlth               253680 non-null  int64\n",
      " 14  MentHlth              253680 non-null  int64\n",
      " 15  PhysHlth              253680 non-null  int64\n",
      " 16  DiffWalk              253680 non-null  int64\n",
      " 17  Sex                   253680 non-null  int64\n",
      " 18  Age                   253680 non-null  int64\n",
      " 19  Education             253680 non-null  int64\n",
      " 20  Income                253680 non-null  int64\n",
      " 21  target                253680 non-null  int64\n",
      "dtypes: int64(22)\n",
      "memory usage: 42.6 MB\n",
      "None\n",
      "\n",
      "Statistik deskriptif:\n",
      "              HighBP       HighChol      CholCheck            BMI  \\\n",
      "count  253680.000000  253680.000000  253680.000000  253680.000000   \n",
      "mean        0.429001       0.424121       0.962670      28.382364   \n",
      "std         0.494934       0.494210       0.189571       6.608694   \n",
      "min         0.000000       0.000000       0.000000      12.000000   \n",
      "25%         0.000000       0.000000       1.000000      24.000000   \n",
      "50%         0.000000       0.000000       1.000000      27.000000   \n",
      "75%         1.000000       1.000000       1.000000      31.000000   \n",
      "max         1.000000       1.000000       1.000000      98.000000   \n",
      "\n",
      "              Smoker         Stroke  HeartDiseaseorAttack   PhysActivity  \\\n",
      "count  253680.000000  253680.000000         253680.000000  253680.000000   \n",
      "mean        0.443169       0.040571              0.094186       0.756544   \n",
      "std         0.496761       0.197294              0.292087       0.429169   \n",
      "min         0.000000       0.000000              0.000000       0.000000   \n",
      "25%         0.000000       0.000000              0.000000       1.000000   \n",
      "50%         0.000000       0.000000              0.000000       1.000000   \n",
      "75%         1.000000       0.000000              0.000000       1.000000   \n",
      "max         1.000000       1.000000              1.000000       1.000000   \n",
      "\n",
      "              Fruits        Veggies  ...    NoDocbcCost        GenHlth  \\\n",
      "count  253680.000000  253680.000000  ...  253680.000000  253680.000000   \n",
      "mean        0.634256       0.811420  ...       0.084177       2.511392   \n",
      "std         0.481639       0.391175  ...       0.277654       1.068477   \n",
      "min         0.000000       0.000000  ...       0.000000       1.000000   \n",
      "25%         0.000000       1.000000  ...       0.000000       2.000000   \n",
      "50%         1.000000       1.000000  ...       0.000000       2.000000   \n",
      "75%         1.000000       1.000000  ...       0.000000       3.000000   \n",
      "max         1.000000       1.000000  ...       1.000000       5.000000   \n",
      "\n",
      "            MentHlth       PhysHlth       DiffWalk            Sex  \\\n",
      "count  253680.000000  253680.000000  253680.000000  253680.000000   \n",
      "mean        3.184772       4.242081       0.168224       0.440342   \n",
      "std         7.412847       8.717951       0.374066       0.496429   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       0.000000       0.000000       0.000000   \n",
      "75%         2.000000       3.000000       0.000000       1.000000   \n",
      "max        30.000000      30.000000       1.000000       1.000000   \n",
      "\n",
      "                 Age      Education         Income         target  \n",
      "count  253680.000000  253680.000000  253680.000000  253680.000000  \n",
      "mean        8.032119       5.050434       6.053875       0.139333  \n",
      "std         3.054220       0.985774       2.071148       0.346294  \n",
      "min         1.000000       1.000000       1.000000       0.000000  \n",
      "25%         6.000000       4.000000       5.000000       0.000000  \n",
      "50%         8.000000       5.000000       7.000000       0.000000  \n",
      "75%        10.000000       6.000000       8.000000       0.000000  \n",
      "max        13.000000       6.000000       8.000000       1.000000  \n",
      "\n",
      "[8 rows x 22 columns]\n",
      "\n",
      "Distribusi kelas target:\n",
      "target\n",
      "0    218334\n",
      "1     35346\n",
      "Name: count, dtype: int64\n",
      "Rasio kelas: 6.18:1\n",
      "\n",
      "=== 2. Preprocessing ===\n",
      "Fitur shape: (253680, 21)\n",
      "Target shape: (253680,)\n",
      "Data setelah scaling (sample):\n",
      "     HighBP  HighChol  CholCheck       BMI    Smoker    Stroke  \\\n",
      "0  1.153688  1.165254   0.196922  1.757936  1.120927 -0.205637   \n",
      "1 -0.866785 -0.858182  -5.078164 -0.511806  1.120927 -0.205637   \n",
      "2  1.153688  1.165254   0.196922 -0.057858 -0.892119 -0.205637   \n",
      "3  1.153688 -0.858182   0.196922 -0.209174 -0.892119 -0.205637   \n",
      "4  1.153688  1.165254   0.196922 -0.663122 -0.892119 -0.205637   \n",
      "\n",
      "   HeartDiseaseorAttack  PhysActivity    Fruits   Veggies  ...  AnyHealthcare  \\\n",
      "0             -0.322458     -1.762814 -1.316872  0.482087  ...       0.226863   \n",
      "1             -0.322458      0.567275 -1.316872 -2.074316  ...      -4.407954   \n",
      "2             -0.322458     -1.762814  0.759375 -2.074316  ...       0.226863   \n",
      "3             -0.322458      0.567275  0.759375  0.482087  ...       0.226863   \n",
      "4             -0.322458      0.567275  0.759375  0.482087  ...       0.226863   \n",
      "\n",
      "   NoDocbcCost   GenHlth  MentHlth  PhysHlth  DiffWalk       Sex       Age  \\\n",
      "0    -0.303173  2.329121  1.998592  1.233999  2.223615 -0.887021  0.316900   \n",
      "1     3.298445  0.457294 -0.429630 -0.486592 -0.449718 -0.887021 -0.337933   \n",
      "2     3.298445  2.329121  3.617407  2.954590  2.223615 -0.887021  0.316900   \n",
      "3    -0.303173 -0.478619 -0.429630 -0.486592 -0.449718 -0.887021  0.971733   \n",
      "4    -0.303173 -0.478619 -0.024926 -0.486592 -0.449718 -0.887021  0.971733   \n",
      "\n",
      "   Education    Income  \n",
      "0  -1.065595 -1.474487  \n",
      "1   0.963272 -2.440138  \n",
      "2  -1.065595  0.939638  \n",
      "3  -2.080028 -0.026012  \n",
      "4  -0.051162 -0.991662  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "Korelasi fitur dengan target:\n",
      "target                  1.000000\n",
      "GenHlth                 0.293569\n",
      "HighBP                  0.263129\n",
      "DiffWalk                0.218344\n",
      "BMI                     0.216843\n",
      "HighChol                0.200276\n",
      "Age                     0.177442\n",
      "HeartDiseaseorAttack    0.177282\n",
      "PhysHlth                0.171337\n",
      "Stroke                  0.105816\n",
      "MentHlth                0.069315\n",
      "CholCheck               0.064761\n",
      "Smoker                  0.060789\n",
      "NoDocbcCost             0.031433\n",
      "Sex                     0.031430\n",
      "AnyHealthcare           0.016255\n",
      "Fruits                 -0.040779\n",
      "Veggies                -0.056584\n",
      "HvyAlcoholConsump      -0.057056\n",
      "PhysActivity           -0.118133\n",
      "Education              -0.124456\n",
      "Income                 -0.163919\n",
      "Name: target, dtype: float64\n",
      "\n",
      "Membuat fitur interaksi baru...\n",
      "Jumlah fitur setelah menambahkan interaksi: 26\n",
      "\n",
      "=== 3. Split Train/Test (75:25) ===\n",
      "X_train shape: (190260, 26)\n",
      "X_test shape: (63420, 26)\n",
      "Distribusi kelas di training set: [163751  26509]\n",
      "Distribusi kelas di testing set: [54583  8837]\n",
      "\n",
      "=== 4. Feature Selection dengan Random Forest ===\n",
      "Feature importances:\n",
      "                 Feature  Importance\n",
      "25       Health_Combined    0.100190\n",
      "21             BMI_X_Age    0.075528\n",
      "20                Income    0.075453\n",
      "13               GenHlth    0.074909\n",
      "3                    BMI    0.061249\n",
      "18                   Age    0.056498\n",
      "22          BMI_X_HighBP    0.055379\n",
      "19             Education    0.053133\n",
      "0                 HighBP    0.051735\n",
      "24        BMI_X_HighChol    0.050468\n",
      "15              PhysHlth    0.043753\n",
      "23          Age_X_HighBP    0.043684\n",
      "14              MentHlth    0.032443\n",
      "4                 Smoker    0.028249\n",
      "1               HighChol    0.027791\n",
      "8                 Fruits    0.026935\n",
      "17                   Sex    0.025623\n",
      "7           PhysActivity    0.022344\n",
      "16              DiffWalk    0.020611\n",
      "9                Veggies    0.020543\n",
      "6   HeartDiseaseorAttack    0.016269\n",
      "12           NoDocbcCost    0.009628\n",
      "5                 Stroke    0.008583\n",
      "10     HvyAlcoholConsump    0.008282\n",
      "11         AnyHealthcare    0.006252\n",
      "2              CholCheck    0.004468\n",
      "Jumlah fitur terpilih: 12 dari 26\n",
      "Fitur terpilih: ['HighBP', 'BMI', 'GenHlth', 'PhysHlth', 'Age', 'Education', 'Income', 'BMI_X_Age', 'BMI_X_HighBP', 'Age_X_HighBP', 'BMI_X_HighChol', 'Health_Combined']\n",
      "\n",
      "=== 5. Resampling untuk Mengatasi Ketidakseimbangan Kelas ===\n",
      "Bentuk data training sebelum resampling: (190260, 12)\n",
      "Distribusi kelas sebelum resampling: [163751  26509]\n",
      "Bentuk data training setelah resampling: (184218, 12)\n",
      "Distribusi kelas setelah resampling: [102343  81875]\n",
      "\n",
      "=== 6. Train Final Model (XGBoost with focus on recall) ===\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1681\u001B[39m, in \u001B[36mParallel._get_outputs\u001B[39m\u001B[34m(self, iterator, pre_dispatch)\u001B[39m\n\u001B[32m   1680\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backend.retrieval_context():\n\u001B[32m-> \u001B[39m\u001B[32m1681\u001B[39m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m._retrieve()\n\u001B[32m   1683\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[32m   1684\u001B[39m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[32m   1685\u001B[39m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[32m   1686\u001B[39m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1799\u001B[39m, in \u001B[36mParallel._retrieve\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1796\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (nb_jobs == \u001B[32m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[32m   1797\u001B[39m     \u001B[38;5;28mself\u001B[39m._jobs[\u001B[32m0\u001B[39m].get_status(timeout=\u001B[38;5;28mself\u001B[39m.timeout) == TASK_PENDING\n\u001B[32m   1798\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1799\u001B[39m     \u001B[43mtime\u001B[49m\u001B[43m.\u001B[49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1800\u001B[39m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 232\u001B[39m\n\u001B[32m    218\u001B[39m xgb_random = RandomizedSearchCV(\n\u001B[32m    219\u001B[39m     xgb.XGBClassifier(objective=\u001B[33m'\u001B[39m\u001B[33mbinary:logistic\u001B[39m\u001B[33m'\u001B[39m, random_state=\u001B[32m42\u001B[39m,\n\u001B[32m    220\u001B[39m                      use_label_encoder=\u001B[38;5;28;01mFalse\u001B[39;00m, eval_metric=\u001B[33m'\u001B[39m\u001B[33mlogloss\u001B[39m\u001B[33m'\u001B[39m),\n\u001B[32m   (...)\u001B[39m\u001B[32m    227\u001B[39m     random_state=\u001B[32m42\u001B[39m\n\u001B[32m    228\u001B[39m )\n\u001B[32m    230\u001B[39m \u001B[38;5;66;03m# Train the model on the resampled data\u001B[39;00m\n\u001B[32m    231\u001B[39m \u001B[38;5;66;03m# Note: Remove eval_set and early_stopping_rounds from here\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m232\u001B[39m \u001B[43mxgb_random\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_resampled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_resampled\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    234\u001B[39m \u001B[38;5;66;03m# Best model parameters\u001B[39;00m\n\u001B[32m    235\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mBest parameters:\u001B[39m\u001B[33m\"\u001B[39m, xgb_random.best_params_)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1382\u001B[39m     estimator._validate_params()\n\u001B[32m   1384\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1385\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1386\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1387\u001B[39m     )\n\u001B[32m   1388\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1389\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001B[39m, in \u001B[36mBaseSearchCV.fit\u001B[39m\u001B[34m(self, X, y, **params)\u001B[39m\n\u001B[32m   1018\u001B[39m     results = \u001B[38;5;28mself\u001B[39m._format_results(\n\u001B[32m   1019\u001B[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[32m   1020\u001B[39m     )\n\u001B[32m   1022\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[32m-> \u001B[39m\u001B[32m1024\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1026\u001B[39m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[32m   1027\u001B[39m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[32m   1028\u001B[39m first_test_score = all_out[\u001B[32m0\u001B[39m][\u001B[33m\"\u001B[39m\u001B[33mtest_scores\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001B[39m, in \u001B[36mRandomizedSearchCV._run_search\u001B[39m\u001B[34m(self, evaluate_candidates)\u001B[39m\n\u001B[32m   1949\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[32m   1950\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1951\u001B[39m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1952\u001B[39m \u001B[43m        \u001B[49m\u001B[43mParameterSampler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1953\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mparam_distributions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mn_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrandom_state\u001B[49m\n\u001B[32m   1954\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1955\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001B[39m, in \u001B[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[39m\u001B[34m(candidate_params, cv, more_results)\u001B[39m\n\u001B[32m    962\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.verbose > \u001B[32m0\u001B[39m:\n\u001B[32m    963\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[32m    964\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[33m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[33m candidates,\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    965\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[33m fits\u001B[39m\u001B[33m\"\u001B[39m.format(\n\u001B[32m    966\u001B[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001B[32m    967\u001B[39m         )\n\u001B[32m    968\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m970\u001B[39m out = \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    971\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    972\u001B[39m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    973\u001B[39m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    974\u001B[39m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    975\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    976\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    977\u001B[39m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m=\u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    978\u001B[39m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    979\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    980\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    981\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    982\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    983\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    984\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[43m.\u001B[49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mrouted_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43msplitter\u001B[49m\u001B[43m.\u001B[49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    985\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    986\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    988\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) < \u001B[32m1\u001B[39m:\n\u001B[32m    989\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    990\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mNo fits were performed. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    991\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mWas the CV iterator empty? \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    992\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mWere there no candidates?\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    993\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m     72\u001B[39m config = get_config()\n\u001B[32m     73\u001B[39m iterable_with_config = (\n\u001B[32m     74\u001B[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[32m     75\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[32m     76\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m77\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2071\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   2065\u001B[39m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[32m   2066\u001B[39m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[32m   2067\u001B[39m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[32m   2068\u001B[39m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[32m   2069\u001B[39m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[32m-> \u001B[39m\u001B[32m2071\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.return_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1731\u001B[39m, in \u001B[36mParallel._get_outputs\u001B[39m\u001B[34m(self, iterator, pre_dispatch)\u001B[39m\n\u001B[32m   1729\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m:\n\u001B[32m   1730\u001B[39m     \u001B[38;5;28mself\u001B[39m._exception = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1731\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_abort\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1732\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[32m   1733\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m   1734\u001B[39m     \u001B[38;5;66;03m# Store the unconsumed tasks and terminate the workers if necessary\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1645\u001B[39m, in \u001B[36mParallel._abort\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1640\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m._aborted \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(backend, \u001B[33m\"\u001B[39m\u001B[33mabort_everything\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m   1641\u001B[39m     \u001B[38;5;66;03m# If the backend is managed externally we need to make sure\u001B[39;00m\n\u001B[32m   1642\u001B[39m     \u001B[38;5;66;03m# to leave it in a working state to allow for future jobs\u001B[39;00m\n\u001B[32m   1643\u001B[39m     \u001B[38;5;66;03m# scheduling.\u001B[39;00m\n\u001B[32m   1644\u001B[39m     ensure_ready = \u001B[38;5;28mself\u001B[39m._managed_backend\n\u001B[32m-> \u001B[39m\u001B[32m1645\u001B[39m     \u001B[43mbackend\u001B[49m\u001B[43m.\u001B[49m\u001B[43mabort_everything\u001B[49m\u001B[43m(\u001B[49m\u001B[43mensure_ready\u001B[49m\u001B[43m=\u001B[49m\u001B[43mensure_ready\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1646\u001B[39m \u001B[38;5;28mself\u001B[39m._aborted = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\_parallel_backends.py:725\u001B[39m, in \u001B[36mLokyBackend.abort_everything\u001B[39m\u001B[34m(self, ensure_ready)\u001B[39m\n\u001B[32m    723\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mabort_everything\u001B[39m(\u001B[38;5;28mself\u001B[39m, ensure_ready=\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[32m    724\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Shutdown the workers and restart a new one with the same parameters\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m725\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_workers\u001B[49m\u001B[43m.\u001B[49m\u001B[43mterminate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkill_workers\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    726\u001B[39m     \u001B[38;5;28mself\u001B[39m._workers = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    728\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m ensure_ready:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\executor.py:86\u001B[39m, in \u001B[36mMemmappingExecutor.terminate\u001B[39m\u001B[34m(self, kill_workers)\u001B[39m\n\u001B[32m     85\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mterminate\u001B[39m(\u001B[38;5;28mself\u001B[39m, kill_workers=\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m---> \u001B[39m\u001B[32m86\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mshutdown\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkill_workers\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkill_workers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     88\u001B[39m     \u001B[38;5;66;03m# When workers are killed in a brutal manner, they cannot execute the\u001B[39;00m\n\u001B[32m     89\u001B[39m     \u001B[38;5;66;03m# finalizer of their shared memmaps. The refcount of those memmaps may\u001B[39;00m\n\u001B[32m     90\u001B[39m     \u001B[38;5;66;03m# be off by an unknown number, so instead of decref'ing them, we force\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     95\u001B[39m     \u001B[38;5;66;03m# with allow_non_empty=True but if we can't, it will be clean up later\u001B[39;00m\n\u001B[32m     96\u001B[39m     \u001B[38;5;66;03m# on by the resource_tracker.\u001B[39;00m\n\u001B[32m     97\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._submit_resize_lock:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:1333\u001B[39m, in \u001B[36mProcessPoolExecutor.shutdown\u001B[39m\u001B[34m(self, wait, kill_workers)\u001B[39m\n\u001B[32m   1329\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m executor_manager_thread \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m wait:\n\u001B[32m   1330\u001B[39m     \u001B[38;5;66;03m# This locks avoids concurrent join if the interpreter\u001B[39;00m\n\u001B[32m   1331\u001B[39m     \u001B[38;5;66;03m# is shutting down.\u001B[39;00m\n\u001B[32m   1332\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m _global_shutdown_lock:\n\u001B[32m-> \u001B[39m\u001B[32m1333\u001B[39m         \u001B[43mexecutor_manager_thread\u001B[49m\u001B[43m.\u001B[49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1334\u001B[39m         _threads_wakeups.pop(executor_manager_thread, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m   1336\u001B[39m \u001B[38;5;66;03m# To reduce the risk of opening too many files, remove references to\u001B[39;00m\n\u001B[32m   1337\u001B[39m \u001B[38;5;66;03m# objects that use file descriptors.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py:1147\u001B[39m, in \u001B[36mThread.join\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m   1144\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mcannot join current thread\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   1146\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1147\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_wait_for_tstate_lock\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1148\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1149\u001B[39m     \u001B[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001B[39;00m\n\u001B[32m   1150\u001B[39m     \u001B[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001B[39;00m\n\u001B[32m   1151\u001B[39m     \u001B[38;5;28mself\u001B[39m._wait_for_tstate_lock(timeout=\u001B[38;5;28mmax\u001B[39m(timeout, \u001B[32m0\u001B[39m))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py:1167\u001B[39m, in \u001B[36mThread._wait_for_tstate_lock\u001B[39m\u001B[34m(self, block, timeout)\u001B[39m\n\u001B[32m   1164\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m   1166\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1167\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mlock\u001B[49m\u001B[43m.\u001B[49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[32m   1168\u001B[39m         lock.release()\n\u001B[32m   1169\u001B[39m         \u001B[38;5;28mself\u001B[39m._stop()\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.96      0.63      0.76     54583\n",
    "           1       0.27      0.85      0.41      8837\n",
    "\n",
    "    accuracy                           0.66     63420\n",
    "   macro avg       0.62      0.74      0.58     63420\n",
    "weighted avg       0.87      0.66      0.71     63420"
   ],
   "id": "ac2f0c673b4860b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T08:56:29.799Z",
     "start_time": "2025-05-31T08:56:29.581150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../dataset/cdc_diabetes_health_indicators.csv')\n",
    "print(data['target'].value_counts())\n"
   ],
   "id": "46135a5cc57f0a64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    218334\n",
      "1     35346\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
